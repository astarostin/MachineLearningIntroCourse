Этап 1.

1. Признаки, имеющие пропуски для своих значений (в скобках - количество пропусков):
first_blood_time (19553)
first_blood_team (19553)
first_blood_player1 (19553)
first_blood_player2 (43987)
radiant_bottle_time (15691)
radiant_courier_time (692)
radiant_flying_courier_time (27479)
radiant_first_ward_time (1836)
dire_bottle_time (16143)
dire_courier_time (676)
dire_flying_courier_time (26098)
dire_first_ward_time (1826)

Для признака first_blood_player2 пропуски означают, что либо событие "первая кровь" не успело произойти за первые 5 минут в данном матче, либо событие произошло, но в нем участвовал только player1.
Для признака dire_courier_time пропуски означают, что команда Dire не успела приобрести предмет courier за первые 5 минут матча.

2. Столбец, содержащий целевую переменную, называется radiant_win.

3. Кросс-валидация для градиентного бустинга с 30 деревьями заняла 4 минуты 2 секунды. При этом качество по метрике AUC-ROC составило 0.68992696.

4. Эксперименты показали, что качество обучения растет с увеличением числа деревьев. На 40 деревьях оно составило 0.69429419. 
При ограничении обучающей выборки в 3000 объектов, взятых случайным образом, были протестированы результаты для бустинга с числом деревьев от 30 до 200 с шагом 10: наилучшее качество было на 130 деревьях и составило 0.69793210.
Однако увеличение числа деревьев ведет к замедлению скорости обучения. Чтобы ускорить обучение при увеличении количества деревьев, можно ограничить глубину деревьев параметром max_depth, или ограничить число листьев параметром max_leaf_nodes.

Этап 2.

1. Качество логистической регрессии над всеми исходными признаками - 0.71636667, то есть примерно на 3.18% лучше, чем у градиентного бустинга. Это можно объяснить тем, что логистическая регрессия более устойчива к переобчучению засчет регуляризации. Она работает значительно быстрее, чем градиентный бустинг, примерно 21 секунду. Таким образом, логистическая регрессия удобнее для данной задачи.

2. Удаление категориальных признаков дало качество 0.71639445, т.е. малое улучшение качества. 
Можно предположить, что использование категориальных признаков в качестве числовых не вносило большого ущерба, поскольку идентификаторы героев - числа в диапазоне от 1 до 112, т.е. разброс чисел небольшой, почти все они встречаются в данных. 

3. Число различных идентификаторов героев на данной выборке - 108.

4. При добавлении "мешка слов" по героям получилось качество 0.75176348, то есть улучшилось на 4.9% относительно предыдущего варианта. Таким образом, введение новых признаков для героев по принципу "мешка слов" дает заметное улучшение качества, потому что такой подход в более явном виде отражает присутствие в команде одних персонажей и отсутствие других, что благоприятно влияет на обучение.

5. Тестовая выборка обрабатывалась лучшим алгоритмом - логистической регрессией с учетом "мешка слов" и параметром регуляризации 0.1. Минимальное значение прогноза на тестовой выборке - 0.0085. Максимальное значение прогноза на тестовой выборке - 0.0085.